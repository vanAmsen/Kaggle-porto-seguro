{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "#import joypy\n",
    "import re\n",
    "#from IPython.display import display, HTML\n",
    "#import ipywidgets as widgets # for later\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My own function - It is less efficient\n",
    "\n",
    "def Create_OHE(dataframe,variables,limit):\n",
    "    df = dataframe.copy()\n",
    "    for variable in variables:\n",
    "        if len(pd.unique(df[variable])) < limit and len(pd.unique(df[variable])) > 2:\n",
    "            columnsv = [variable + '_ohe' + str(value) for value in pd.unique(df[variable]).tolist()]\n",
    "            dummy = pd.get_dummies(df[variable])\n",
    "            dummy.columns = columnsv\n",
    "            df = df.drop(variable,axis=1).copy().join(dummy)\n",
    "            #print(variable,columnsv)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MetaDataTypes(df,types_var=['cat','bin','target']):\n",
    "    # Classifying the variables in the data\n",
    "    variables = []\n",
    "    vartype = {}\n",
    "    for variable in df.columns:\n",
    "        for types in types_var:\n",
    "            ty = \"None\"\n",
    "            if df[variable].dtype == int:\n",
    "                tybin = \"ordinal\"\n",
    "            elif df[variable].dtype == float:\n",
    "                tybin = \"continuous\"\n",
    "            match = re.search('^.*'+types+'.*$',variable)\n",
    "            if match:\n",
    "                ty = types\n",
    "                if re.search('^.*bin.*$',variable):\n",
    "                    tybin='binary'\n",
    "                if re.search('^.*cat.*$',variable):\n",
    "                    tybin='categorical'\n",
    "                if 'target' in variable:\n",
    "                    tybin = 'binary'\n",
    "                break\n",
    "\n",
    "            \n",
    "        variables.append([variable,ty,tybin])\n",
    "        \n",
    "    variablesdf = pd.DataFrame(variables,columns=['name','type','bin'])\n",
    "    \n",
    "    for i in ['ordinal','continuous','binary','categorical']:\n",
    "        vartype[i]=variablesdf.name[(variablesdf.bin==i)]\n",
    "\n",
    "    # Creating dataframe containing variables\n",
    "    return variablesdf,vartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types_var = ['ind','reg','car', 'calc','target','id']\n",
    "variablesdf,vartype = MetaDataTypes(train,types_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(vartype['binary'][1]) #Deleting target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MICC_CARDINALITY_TRANSFORM(dataframe,target, variables, k=1, f=1,heuristic = False, drop=True):\n",
    "    \n",
    "    def lb_card(n,k,f):\n",
    "        lb = 1/(1+np.exp(-(n-k)/f))\n",
    "        return lb\n",
    "    if type(variables) == str:\n",
    "        variables = [variables]\n",
    "    for variable in variables:\n",
    "        \n",
    "        df = dataframe.copy()\n",
    "        g = pd.DataFrame(df.groupby(variable).count().iloc[:,0]).reset_index()\n",
    "        p = pd.DataFrame(df.groupby(variable).count().iloc[:,0]).reset_index()\n",
    "\n",
    "        if heuristic == True:\n",
    "            k = df[target][df[target]>0].count()/2\n",
    "            f = df[target].count()/10000*5\n",
    "        posterior = pd.DataFrame(df[df[target]>0]\n",
    "                                 .groupby(variable).count().iloc[:,0]).reset_index().iloc[:,-1]/g.iloc[:,-1]\n",
    "        prior = df[df[target]>0].count().iloc[0]/df.count().iloc[0]\n",
    "\n",
    "        variable_tf = lb_card(g.iloc[:,-1],k,f)*posterior + (1-lb_card(g.iloc[:,-1],k,f))*prior\n",
    "\n",
    "        g.iloc[:,-1] = variable_tf.values\n",
    "        g['prior'] = prior\n",
    "        g['posterior'] = posterior\n",
    "\n",
    "        df[variable+'_micc'] = df.merge(g,on=variable,how='left').iloc[:,-1]\n",
    "        \n",
    "        if drop==True:\n",
    "            df.drop(variable,axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def FREQUENCY_CARDINALITY(dataframe,variables,drop=True):\n",
    "    \n",
    "    if type(variables) == str:\n",
    "        variables = [variables]\n",
    "        \n",
    "    for variable in variables:\n",
    "        df = dataframe.copy()\n",
    "        g = pd.DataFrame(df.groupby(variable).count().iloc[:,0]).reset_index()\n",
    "        g.iloc[:,-1] = g.iloc[:,-1]/df.count().iloc[0]\n",
    "        g.iloc[:,-1] = g.sort_values(by=g.columns[-1]).cumsum().iloc[:,-1]\n",
    "        df[variable+'_freq'] = df.merge(g,on=variable,how='left').iloc[:,-1]\n",
    "        \n",
    "        if drop==True:\n",
    "            df.drop(variable,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def CAT_TRANSFORM(dataframe,dataframe_prep,variables, limitinf=20,limitsup=200):\n",
    "# limitinf = 20 # the number to consider high cardinality. Variables below will be set with one-hot encoding\n",
    "# limitsup = 50 # the number to consider very-high cardinality. Variables above will be set with one-hot encoding\n",
    "    df = dataframe.copy()\n",
    "    df_prep = dataframe_prep.copy()\n",
    "\n",
    "    for variable in variables:\n",
    "\n",
    "        if len(pd.unique(df[variable])) < limitinf and len(pd.unique(df[variable])) > 2:\n",
    "            pass\n",
    "\n",
    "        elif len(pd.unique(df[variable])) < limitsup and len(pd.unique(df[variable])) >= limitinf:\n",
    "            df_prep = FREQUENCY_CARDINALITY(df_prep,variable)\n",
    "            print('freq',variable)\n",
    "\n",
    "        elif len(pd.unique(df[variable])) >= limitsup:\n",
    "            df_prep = MICC_CARDINALITY_TRANSFORM(df_prep,'target',variable,heuristic=True)\n",
    "            print('micci',variable)\n",
    "    \n",
    "    return df_prep\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FILL_MISSING(df, missing_value = np.NaN):\n",
    "    ''' Fills the missing values with their modes'''\n",
    "    \n",
    "    if missing_value != np.NaN:\n",
    "        df.replace(missing_value,np.NaN,inplace=True)\n",
    "    col = df.columns\n",
    "    for i in col:\n",
    "        if df[i].isnull().sum()>0:\n",
    "            df[i].fillna(df[i].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep = train.copy()\n",
    "test_prep  = test.copy()\n",
    "train_prep = train.drop(variablesdf.name[variablesdf['type']=='calc'],axis=1)\n",
    "train_prep = train_prep.drop('target',axis=1)\n",
    "test_prep = test.drop(variablesdf.name[variablesdf['type']=='calc'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types_var = ['ind','reg','car', 'calc','target','id']\n",
    "variablesdf,vartype = MetaDataTypes(train_prep,types_var)\n",
    "\n",
    "FILL_MISSING(train_prep,-1)\n",
    "FILL_MISSING(test_prep,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OHE(df1,df2,column):\n",
    "    cat_col = column\n",
    "    #cat_col = df.select_dtypes(include =['category']).columns\n",
    "    len_df1 = df1.shape[0]\n",
    "    \n",
    "    df = pd.concat([df1,df2],ignore_index=True)\n",
    "    c2,c3 = [],{}\n",
    "    \n",
    "    print('Categorical feature',len(column))\n",
    "    for c in cat_col:\n",
    "        if df[c].nunique()>2 :\n",
    "            c2.append(c)\n",
    "            c3[c] = 'ohe_'+c\n",
    "    \n",
    "    df = pd.get_dummies(df, prefix=c3, columns=c2,drop_first=True)\n",
    "\n",
    "    df1 = df.loc[:len_df1-1]\n",
    "    df2 = df.loc[len_df1:]\n",
    "    print('Train',df1.shape)\n",
    "    print('Test',df2.shape)\n",
    "    return df1,df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outlier(df,columns):\n",
    "    for i in columns:\n",
    "        quartile_1,quartile_3 = np.percentile(df[i],[25,75])\n",
    "        quartile_f,quartile_l = np.percentile(df[i],[1,99])\n",
    "        IQR = quartile_3-quartile_1\n",
    "        lower_bound = quartile_1 - (1.5*IQR)\n",
    "        upper_bound = quartile_3 + (1.5*IQR)\n",
    "        print(lower_bound,upper_bound)\n",
    "        print(quartile_f,quartile_l)\n",
    "        \n",
    "        df[i].loc[df[i] < lower_bound] = quartile_f\n",
    "        df[i].loc[df[i] > upper_bound] = quartile_l\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08484029175 1.54909582495\n",
      "0.4183300133 1.8521946442\n",
      "0.190569415 0.525658351\n",
      "0.3155946768 0.5656854249\n",
      "0.31788087655 1.25917611615\n",
      "0.448300509774 1.61761689551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davi/Envs/machinepy3/machinepy3/lib/python3.5/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2891566485 0.4608812941\n",
      "0.2887905816 0.5234500931\n",
      "0.08156262285 1.55455860645\n",
      "0.4190763654 1.8521946442\n",
      "0.190569415 0.525658351\n",
      "0.3155946768 0.5656854249\n",
      "0.318887063862 1.25847823656\n",
      "0.4485283558 1.61723992314\n",
      "0.2891566485 0.4608812941\n",
      "0.2887905816 0.5234500931\n"
     ]
    }
   ],
   "source": [
    "num_col =['ps_reg_03', 'ps_car_12', 'ps_car_13', 'ps_car_14']\n",
    "outlier(train_prep,num_col)\n",
    "outlier(test_prep,num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prep.shape\n",
    "tot_cat_col = ['target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', \n",
    "               'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', \n",
    "               'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', \n",
    "               'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin', 'ps_ind_17_bin', \n",
    "               'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_car_01_cat', 'ps_car_02_cat', \n",
    "               'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', \n",
    "               'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11', 'ps_car_15']\n",
    "len(tot_cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "c = list(itertools.chain(vartype['categorical'].values,vartype['binary'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': 6     ps_ind_06_bin\n",
       " 7     ps_ind_07_bin\n",
       " 8     ps_ind_08_bin\n",
       " 9     ps_ind_09_bin\n",
       " 10    ps_ind_10_bin\n",
       " 11    ps_ind_11_bin\n",
       " 12    ps_ind_12_bin\n",
       " 13    ps_ind_13_bin\n",
       " 16    ps_ind_16_bin\n",
       " 17    ps_ind_17_bin\n",
       " 18    ps_ind_18_bin\n",
       " Name: name, dtype: object, 'categorical': 2     ps_ind_02_cat\n",
       " 4     ps_ind_04_cat\n",
       " 5     ps_ind_05_cat\n",
       " 22    ps_car_01_cat\n",
       " 23    ps_car_02_cat\n",
       " 24    ps_car_03_cat\n",
       " 25    ps_car_04_cat\n",
       " 26    ps_car_05_cat\n",
       " 27    ps_car_06_cat\n",
       " 28    ps_car_07_cat\n",
       " 29    ps_car_08_cat\n",
       " 30    ps_car_09_cat\n",
       " 31    ps_car_10_cat\n",
       " 32    ps_car_11_cat\n",
       " Name: name, dtype: object, 'continuous': 19    ps_reg_01\n",
       " 20    ps_reg_02\n",
       " 21    ps_reg_03\n",
       " 34    ps_car_12\n",
       " 35    ps_car_13\n",
       " 36    ps_car_14\n",
       " 37    ps_car_15\n",
       " Name: name, dtype: object, 'ordinal': 0            id\n",
       " 1     ps_ind_01\n",
       " 3     ps_ind_03\n",
       " 14    ps_ind_14\n",
       " 15    ps_ind_15\n",
       " 33    ps_car_11\n",
       " Name: name, dtype: object}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical feature 14\n",
      "Train (595212, 185)\n",
      "Test (892816, 185)\n"
     ]
    }
   ],
   "source": [
    "train1,test1 = OHE(train_prep,test_prep,vartype['categorical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical feature 11\n",
      "Train (595212, 185)\n",
      "Test (892816, 185)\n"
     ]
    }
   ],
   "source": [
    "train1,test1 = OHE(train1,test1,vartype['binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep = Create_OHE(train_prep,vartype['categorical'].values,120)\n",
    "test_prep = Create_OHE(test_prep,vartype['categorical'].values,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 193)\n",
      "(892816, 193)\n"
     ]
    }
   ],
   "source": [
    "print(train_prep.shape)\n",
    "print(test_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prep = CAT_TRANSFORM(train, train_prep,vartype['categorical']) \n",
    "\n",
    "train_prep['ps_car_11_cat'] = train['ps_car_11_cat']\n",
    "key_cat = train_prep[['ps_car_11_cat','ps_car_11_cat_freq']]\n",
    "key_cat = key_cat[key_cat[['ps_car_11_cat','ps_car_11_cat_freq']].duplicated()==False]\n",
    "train_prep.drop(['ps_car_11_cat'],axis=1,inplace=True)\n",
    "\n",
    "test_prep = test_prep.merge(right=key_cat,on=['ps_car_11_cat']).drop('ps_car_11_cat',axis=1)\n",
    "\n",
    "test_prep = test_prep[train_prep.drop(['target'],axis=1).columns.values] # Adjust the columns order\n",
    "train_prep.drop(['target'],axis=1).columns == test_prep.columns #Check to see if all are equal\n",
    "\n",
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machinepy3)",
   "language": "python",
   "name": "machinepy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
