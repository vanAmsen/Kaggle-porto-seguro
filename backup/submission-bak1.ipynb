{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Porto Seguro - Initial submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has already been explored. So now I will focus on feature engineering, model trainning and submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#import joypy\n",
    "import re\n",
    "#from IPython.display import display, HTML\n",
    "#import ipywidgets as widgets # for later\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "rc={'savefig.dpi': 75, 'figure.autolayout': False, 'figure.figsize': [12, 8], 'axes.labelsize': 12,\\\n",
    "   'axes.titlesize': 12, 'font.size': 12, 'lines.linewidth': 2.0, 'lines.markersize': 8, 'legend.fontsize': 12,\\\n",
    "   'xtick.labelsize': 12, 'ytick.labelsize': 12}\n",
    "\n",
    "sns.set(style=\"darkgrid\", color_codes=True,rc=rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating variables by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MetaDataTypes(df,types_var=['cat','bin','target']):\n",
    "    # Classifying the variables in the data\n",
    "    variables = []\n",
    "    vartype = {}\n",
    "    for variable in df.columns:\n",
    "        for types in types_var:\n",
    "            ty = \"None\"\n",
    "            if df[variable].dtype == int:\n",
    "                tybin = \"ordinal\"\n",
    "            elif df[variable].dtype == float:\n",
    "                tybin = \"continuous\"\n",
    "            match = re.search('^.*'+types+'.*$',variable)\n",
    "            if match:\n",
    "                ty = types\n",
    "                if re.search('^.*bin.*$',variable):\n",
    "                    tybin='binary'\n",
    "                if re.search('^.*cat.*$',variable):\n",
    "                    tybin='categorical'\n",
    "                if 'target' in variable:\n",
    "                    tybin = 'binary'\n",
    "                break\n",
    "\n",
    "            \n",
    "        variables.append([variable,ty,tybin])\n",
    "        \n",
    "    variablesdf = pd.DataFrame(variables,columns=['name','type','bin'])\n",
    "    \n",
    "    for i in ['ordinal','continuous','binary','categorical']:\n",
    "        vartype[i]=variablesdf.name[(variablesdf.bin==i)]\n",
    "\n",
    "    # Creating dataframe containing variables\n",
    "    return variablesdf,vartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_var = ['ind','reg','car', 'calc','target','id']\n",
    "variablesdf,vartype = MetaDataTypes(train,types_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code from https://github.com/felipeeeantunes/udacity_live\n",
    "\n",
    "# In this code, it seems it is not droping the original variables\n",
    "one_hot = {c: list(train[c].unique()) for c in train.columns if c not in ['id','target']}\n",
    "def OHE_by_unique(train, one_hot, limit):\n",
    "    \n",
    "    #ONE-HOT enconde features with more than 2 and less than 'limit' unique values\n",
    "    df = train.copy()\n",
    "    for c in one_hot:\n",
    "        if len(one_hot[c])>2 and len(one_hot[c]) < limit:\n",
    "            #print(c,one_hot[c])\n",
    "            for val in one_hot[c]:\n",
    "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "            df = df.drop(c,axis=1) # Davi Barreira - 5/11/2017\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My own function - It is less efficient\n",
    "\n",
    "def Create_OHE(dataframe,variables,limit):\n",
    "    df = dataframe.copy()\n",
    "    for variable in variables:\n",
    "        if len(pd.unique(train[variable])) < limit and len(pd.unique(train[variable])) > 2:\n",
    "            columnsv = [variable + '_ohe' + str(value) for value in pd.unique(train[variable]).tolist()]\n",
    "            dummy = pd.get_dummies(train[variable])\n",
    "            dummy.columns = columnsv\n",
    "            df = df.drop(variable,axis=1).copy().join(dummy)\n",
    "            #print(variable,columnsv)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ohe = Create_OHE(train,vartype['categorical'].values,6)\n",
    "#Create_OHE(traindrop,traindrop.columns,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 75)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'ps_ind_02_cat'\n",
    "dummy = pd.get_dummies(train[variable])\n",
    "dummy.columns = columnsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe = train.drop(variable,axis=1).copy().join(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X = np.array(train)\n",
    "y = np.array(y)\n",
    "folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2017).split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val_model(X,y, model, n_splits=3):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "\n",
    "    folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2017).split(X, y))\n",
    "\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_holdout = X[test_idx]\n",
    "        y_holdout = y[test_idx]\n",
    "\n",
    "        print (\"Fit %s fold %d\" % (str(model).split('(')[0], j+1))\n",
    "        model.fit(X_train, y_train)\n",
    "        cross_score = cross_val_score(model, X_holdout, y_holdout, cv=3, scoring='roc_auc')\n",
    "        print(\"    cross_score: %.5f\" % cross_score.mean())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machinepy3)",
   "language": "python",
   "name": "machinepy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
